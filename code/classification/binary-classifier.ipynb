{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, average_precision_score, precision_recall_curve\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nlp_utils as utils\n",
    "from nlp_utils import get_vectorizer\n",
    "\n",
    "from lime import lime_text\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "# Pretty plots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-ticks')\n",
    "sns.set_style('ticks')\n",
    "plt.rcParams['figure.figsize'] = (7, 5)\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "# Display wide columns\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# SH vs Controls (excl. SI)\n",
    "\n",
    "Train on RMH dataset using only SH cases and controls. Test the final model on SI cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "text = \"entities\"\n",
    "class_names = (\"Controls\", \"Self-harm\")\n",
    "    \n",
    "# Undersampling\n",
    "undersample = False\n",
    "n_controls = 10000\n",
    "\n",
    "# Parameters of feature extraction\n",
    "vectorizer_mode = \"select features\"\n",
    "params = {'analyzer' : \"word\",\n",
    "          'ngram_range' : (1,1),\n",
    "          'use_idf' : True,\n",
    "          'mode' : \"select by pvalue\",\n",
    "          'thresh' : 0.001}\n",
    "\n",
    "reduce_dim = False\n",
    "lsa_method = \"svd\"\n",
    "n_components = 100\n",
    "\n",
    "add_length = False # no effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/rmh_train.csv\")\n",
    "if undersample:\n",
    "    df_train = pd.concat([df_train[df_train.SH == 0].sample(n_controls, random_state=42), \n",
    "                          df_train[df_train.SH\n",
    "                                   != 0]], \n",
    "                         axis=0)\n",
    "\n",
    "df_train.SH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.SH.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "\n",
    "clfs = (\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, class_weight=\"balanced\"),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(class_weight=\"balanced\"),\n",
    "    XGBClassifier(objective=\"binary:logistic\"),\n",
    "    CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\"),\n",
    "                           method='isotonic', cv=3),\n",
    "    CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", **tuned_params),\n",
    "                           method='isotonic', cv=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for clf in clfs:\n",
    "    pipe = make_pipeline(vectorizer, clf)\n",
    "    scores = utils.benchmark_cv_score(pipe, df_train[text], y_train, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300, 400]\n",
    "\n",
    "param_grid = {\"calibratedclassifiercv__base_estimator__n_estimators\": n_estimators}\n",
    "\n",
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "clf = CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", \n",
    "                                           use_label_encoder=False), \n",
    "                             method='isotonic', cv=3)\n",
    "pipe = make_pipeline(vectorizer, clf)\n",
    "\n",
    "utils.grid_search_cv(pipe, df_train[text], y_train, \n",
    "                     param_grid, scoring=\"average_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_depth = [2, 4, 6, 8]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4]\n",
    "subsample = [0.3, 0.5, 0.8, 1.0]\n",
    "scale_pos_weight = [1, 10, 50, 100]\n",
    "\n",
    "param_grid = {\"calibratedclassifiercv__base_estimator__max_depth\": max_depth, \n",
    "              \"calibratedclassifiercv__base_estimator__learning_rate\": learning_rate, \n",
    "              \"calibratedclassifiercv__base_estimator__subsample\": subsample, \n",
    "              \"calibratedclassifiercv__base_estimator__scale_pos_weight\": scale_pos_weight\n",
    "             }\n",
    "\n",
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "clf = CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", \n",
    "                                           n_estimators=300, \n",
    "                                           use_label_encoder=False), \n",
    "                             method='isotonic', cv=3)\n",
    "pipe = make_pipeline(vectorizer, clf)\n",
    "\n",
    "utils.random_search_cv(pipe, df_train[text], y_train, \n",
    "                       param_grid, scoring=\"average_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrated XGB on entities:\n",
    "tuned_params = {'n_estimators': 300,\n",
    "                'subsample': 1.0, \n",
    "                'scale_pos_weight': 1, \n",
    "                'max_depth': 6, \n",
    "                'learning_rate': 0.2}\n",
    "# Calibrated XGB on negated entities:\n",
    "# tuned_params = {'n_estimators': 300,\n",
    "#                 'subsample': 1.0, \n",
    "#                 'scale_pos_weight': 1, \n",
    "#                 'max_depth': 8, \n",
    "#                 'learning_rate': 0.3}\n",
    "# Calibrated XGB on linked entities:\n",
    "# tuned_params = {'n_estimators': 200, \n",
    "#                 'subsample': 0.8, \n",
    "#                 'scale_pos_weight': 1, \n",
    "#                 'max_depth': 8, \n",
    "#                 'learning_rate': 0.2}\n",
    "# Calibrated XGB on negated linked entities:\n",
    "# tuned_params = {'n_estimators': 300, \n",
    "#                 'subsample': 1.0, \n",
    "#                 'scale_pos_weight': 1, \n",
    "#                 'max_depth': 6, \n",
    "#                 'learning_rate': 0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "\n",
    "clf = XGBClassifier(objective=\"binary:logistic\",use_label_encoder=False)\n",
    "calibrated_clf = CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", use_label_encoder=False),\n",
    "                                        method='isotonic', cv=3)\n",
    "\n",
    "pipe = make_pipeline(vectorizer, clf)\n",
    "calibrated_pipe = make_pipeline(vectorizer, calibrated_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run cross validation to calibrate the model and select threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_proba = utils.benchmark_cv(pipe, df_train[text], y_train, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_proba_c = utils.benchmark_cv(calibrated_pipe, df_train[text], y_train, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibration plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[0, 1], y=[0, 1], color=sns.color_palette()[0], lw=2, linestyle='--', label=\"Perfectly calibrated\")\n",
    "\n",
    "fop, mpv = calibration_curve(y_train, y_proba[:,1], n_bins=30, normalize=False)\n",
    "sns.lineplot(x=mpv, y=fop, \n",
    "             lw=3, marker='.', markersize=15, \n",
    "             color=sns.color_palette()[1],\n",
    "             label=\"Uncalibrated\");\n",
    "\n",
    "fop, mpv = calibration_curve(y_train, y_proba_c[:,1], n_bins=30, normalize=False)\n",
    "sns.lineplot(x=mpv, y=fop, \n",
    "             lw=3, marker='.', markersize=15, \n",
    "             color=sns.color_palette()[2],\n",
    "             label=\"Calibrated\");\n",
    "\n",
    "plt.legend(fontsize=16, loc=\"upper left\");\n",
    "plt.xlabel(\"Mean predicted value\");\n",
    "plt.ylabel(\"Fraction of positives\");\n",
    "\n",
    "plt.savefig(\"./results/xgboost_calibration.png\", bbox_inches='tight', dpi=300, pad_inches=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_proba[:,1], bins=10, stat=\"count\", \n",
    "             color=sns.color_palette()[1], lw=3, fill=False, \n",
    "             label=\"Uncalibrated\");\n",
    "sns.histplot(y_proba_c[:,1], bins=10, stat=\"count\", \n",
    "             color=sns.color_palette()[2], lw=3, fill=False, \n",
    "             label=\"Calibrated\");\n",
    "plt.ylim([0, 2600]);\n",
    "plt.legend(fontsize=16, loc=\"upper right\");\n",
    "plt.xlabel(\"Mean predicted value\");\n",
    "\n",
    "plt.savefig(\"./results/xgboost_probabilities.png\", bbox_inches='tight', dpi=300, pad_inches=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_threshold(y_train, y_proba):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_proba[:,1])\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    idx = np.argmax(fscore)\n",
    "    thresh = thresholds[idx]\n",
    "    print('Best threshold is %.3f, F1 score=%.3f' % (thresh, fscore[idx]))\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "clf = CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", \n",
    "                                           use_label_encoder=False, \n",
    "                                           **tuned_params), \n",
    "                                        method='isotonic', cv=3)\n",
    "pipe = make_pipeline(vectorizer, clf)\n",
    "y_proba = utils.benchmark_cv(pipe, df_train[text], y_train, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = select_threshold(y_train, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.322\n",
    "vectorizer = get_vectorizer(vectorizer_mode, params)\n",
    "clf = CalibratedClassifierCV(XGBClassifier(objective=\"binary:logistic\", \n",
    "                                           use_label_encoder=False, \n",
    "                                           **tuned_params), \n",
    "                                        method='isotonic', cv=3)\n",
    "pipe = make_pipeline(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(df_train[text], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = '../models/self-harm-nlp-classifier-final-xgboost.sav'\n",
    "joblib.dump(pipe[1], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = '../models/self-harm-nlp-classifier-final-pipe.sav'\n",
    "\n",
    "pipe = joblib.load(filename)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../../data/rmh_prepared.csv\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.SH.values\n",
    "df_test.SH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.322\n",
    "y_proba = pipe.predict_proba(df_test[text])\n",
    "y_pred = utils.evaluate_model(y_test, y_proba, class_names, \"test\", thresh=thresh, digits=3, \n",
    "                              save_figures=False, filename=\"./results/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 3)\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred, normalize=\"true\"), \n",
    "            annot=confusion_matrix(y_test, y_pred),\n",
    "            annot_kws={'fontsize' : 18}, fmt=\"d\",\n",
    "            cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion matrix\");\n",
    "\n",
    "# plt.savefig(\"./results/final_model_CM.png\", bbox_inches='tight', dpi=300, transparent=True, pad_inches=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.sum() / df_test.shape[0] * 100)\n",
    "print(y_test.sum() / df_test.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho = pd.read_csv(\"../data/rmh_holdout.csv\")\n",
    "df_ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ho = df_ho.SH.values\n",
    "df_ho.SH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho.SI.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_ho = pipe.predict_proba(df_ho[text])\n",
    "y_pred = utils.evaluate_model(y_ho, y_proba_ho, class_names, \"hold-out\", thresh=thresh, digits=3, \n",
    "                              save_figures=False, filename=\"./results/final_model_holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[\"y_pred\"] = y_pred\n",
    "\n",
    "df_ho[df_ho.y_pred == 1].SI.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "116/301*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[(df_ho.SI==1) & (df_ho.y_pred==1)].shape[0] / df_ho.SI.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (7, 5)\n",
    "\n",
    "sns.histplot(y_proba[:,1], bins=10, stat=\"count\", \n",
    "             color=sns.color_palette()[1], lw=3, fill=False, \n",
    "             label=\"Test set\");\n",
    "sns.histplot(y_proba_ho[:,1], bins=10, stat=\"count\", \n",
    "             color=sns.color_palette()[2], lw=3, fill=False, \n",
    "             label=\"Holdout set\");\n",
    "plt.ylim([0, 2600]);\n",
    "plt.legend(fontsize=16, loc=\"upper right\");\n",
    "plt.xlabel(\"Mean predicted value\");\n",
    "\n",
    "# plt.savefig(\"./results/final_model_probabilities_holdout.png\", bbox_inches='tight', dpi=300, pad_inches=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-negatives that are SH: no. 0, 5 ; no. 2 should've been Control, same with 100?\n",
    "ind = df_ho[(df_ho.y_pred == 0) & (df_ho.SH == 1) & (df_ho.SI == 0)].index\n",
    "ind.shape\n",
    "\n",
    "# # False-positives that are SI: no. 0,4\n",
    "# ind = df_ho[(df_ho.y_pred == 1) & (df_ho.SH == 0) & (df_ho.SI == 1)].index\n",
    "# ind.shape\n",
    "\n",
    "# False-positives that are Controls: no.7\n",
    "# ind = df_ho[(df_ho.y_pred == 1) & (df_ho.SH == 0) & (df_ho.SI == 0)].index\n",
    "# ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_instance = df_ho.loc[ind[5], \"entities\"]\n",
    "\n",
    "print(\"Original text: \\\"%s\\\"\"% df_ho.loc[ind[5], \"text\"])\n",
    "\n",
    "explainer = lime_text.LimeTextExplainer(class_names=class_names)\n",
    "explained = explainer.explain_instance(txt_instance, pipe.predict_proba, num_features=5)\n",
    "explained.show_in_notebook(text=txt_instance)\n",
    "explained.save_to_file('lime_report5.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained.local_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f\" % explained.local_exp[1][0][1])\n",
    "print(\"%.2f\" % explained.local_exp[1][1][1])\n",
    "print(\"%.2f\" % explained.local_exp[1][2][1])\n",
    "print(\"%.2f\" % explained.local_exp[1][3][1])\n",
    "print(\"%.3f\" % explained.local_exp[1][4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.1e\" % explained.local_exp[1][0][1])\n",
    "print(\"%.1e\" % explained.local_exp[1][1][1])\n",
    "print(\"%.1e\" % explained.local_exp[1][2][1])\n",
    "print(\"%.1e\" % explained.local_exp[1][3][1])\n",
    "print(\"%.1e\" % explained.local_exp[1][4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_ho[ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suicidal ideation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_si = pd.read_csv(\"./data/rmh_SI.csv\")\n",
    "print(df_si.shape)\n",
    "df_si.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_si = calibrated_pipe.predict_proba(df_si[text])\n",
    "df_si['y_pred'] = np.where(y_proba_si[:,1] > thresh_c, 1, 0)\n",
    "df_si.y_pred.sum(), df_si.y_pred.sum() / df_si.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_si[df_si.y_pred == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_instance = df_si.loc[15, \"entities\"]\n",
    "\n",
    "print(\"Original text: \\\"%s\\\"\"% df_si.loc[15, \"text\"])\n",
    "\n",
    "explainer = lime_text.LimeTextExplainer(class_names=class_names)\n",
    "explained = explainer.explain_instance(txt_instance, calibrated_pipe.predict_proba, num_features=5)\n",
    "explained.show_in_notebook(text=txt_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
