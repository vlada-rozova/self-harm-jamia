{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a405c693",
   "metadata": {},
   "source": [
    "# Create a dictionary of misspellings\n",
    "\n",
    "This notebook parses the whole dataset and adds to an empty dict every token starting with an alpha that is not known to the vocabulary. After that, for each misspelled word a corrected version is found using pyspellchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caeaf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vrozova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "import pickle\n",
    "import time\n",
    "from nlp_utils import preprocess, find_pattern\n",
    "from custom_tokenizer import combined_rule_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27855e1b",
   "metadata": {},
   "source": [
    "**Load RMH data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a887f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SH</th>\n",
       "      <th>SI</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>SOB for 5/7, been to GP given prednisolone, co...</td>\n",
       "      <td>sob for 5/7 , been to gp given prednisolone , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>pt has lac down right forehead, to eyebrow, wi...</td>\n",
       "      <td>pt has lac down right forehead , to eyebrow , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>pt expect MBA, trapped for 45mins, #right femu...</td>\n",
       "      <td>pt expect mba , trapped for 45 mins , fracture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>L) sided flank pain same as previous renal col...</td>\n",
       "      <td>left sided flank pain same as previous renal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193</td>\n",
       "      <td>generalised abdo pain and associated headache ...</td>\n",
       "      <td>generalised abdo pain and associated headache ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SH  SI  length                                               text  \\\n",
       "0  0.0 NaN     140  SOB for 5/7, been to GP given prednisolone, co...   \n",
       "1  0.0 NaN     107  pt has lac down right forehead, to eyebrow, wi...   \n",
       "2  0.0 NaN      74  pt expect MBA, trapped for 45mins, #right femu...   \n",
       "3  0.0 NaN     167  L) sided flank pain same as previous renal col...   \n",
       "4  0.0 NaN     193  generalised abdo pain and associated headache ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  sob for 5/7 , been to gp given prednisolone , ...  \n",
       "1  pt has lac down right forehead , to eyebrow , ...  \n",
       "2  pt expect mba , trapped for 45 mins , fracture...  \n",
       "3    left sided flank pain same as previous renal...  \n",
       "4  generalised abdo pain and associated headache ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/spelling_correction/rmh_nospellcorr.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75959dbd",
   "metadata": {},
   "source": [
    "**Create a dictionary of misspellings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c352da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starts_with_alpha(token):\n",
    "    return token == \"\" or token[0].isalpha()\n",
    "\n",
    "def add_misspelling(text):\n",
    "    tokens = text.split()\n",
    "    for token in spell.unknown(tokens):\n",
    "        if starts_with_alpha(token):\n",
    "            misspelled[token] = misspelled.get(token, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f12f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain-specific vocabulary contains 36506 unique words (9127336 words in total).\n"
     ]
    }
   ],
   "source": [
    "# Load a custom word frequency list\n",
    "with open ('../data/spelling_correction/rmh_custom_vocab.txt', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    \n",
    "# Initialise spellchecker with a custom vocab\n",
    "spell = SpellChecker(language=None)\n",
    "spell.word_frequency.load_words(vocab)\n",
    "\n",
    "print(\"Domain-specific vocabulary contains %d unique words (%d words in total).\" % \n",
    "      (len(set(vocab)), len(vocab)))\n",
    "\n",
    "misspelled = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225c6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60561 misspelled words.\n",
      "CPU times: user 25.5 s, sys: 9.51 ms, total: 25.6 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text_clean.apply(add_misspelling)\n",
    "\n",
    "print(\"Found %d misspelled words.\" % len(misspelled))\n",
    "\n",
    "with open('../data/spelling_correction/rmh_misspelled_dict_nocorr.txt', 'wb') as f:\n",
    "    pickle.dump(misspelled, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f251da7",
   "metadata": {},
   "source": [
    "**Find a correct spelling for every misspelled word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9156d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for token in list(misspelled.keys()):\n",
    "    misspelled.update({token : (misspelled[token], spell.correction(token))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744802b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = [0, 5000, 10000, 15000]\n",
    "# end = [5000, 10000, 15000, len(misspelled)]\n",
    "\n",
    "# for i,j in zip(start, end):\n",
    "#     print(i, j)\n",
    "# print(\"Correcting spelling of {} tokens...\".format(len(misspelled)))\n",
    "# i = 0\n",
    "# for token in misspelled:\n",
    "#     misspelled.update({token : (misspelled[token], spell.correction(token))})\n",
    "#     if i % 5000 == 0:\n",
    "#         with open('data/spelling correction/' + filename + 'misspelled', 'a') as f:\n",
    "#             pickle.dump(misspelled, f)\n",
    "#         print(i)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc466a2",
   "metadata": {},
   "source": [
    "### Manually correct misspellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffedeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "del misspelled[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(misspelled.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled.update({\"spont\" : (misspelled[\"spont\"][0], \"spontaneous\")})\n",
    "misspelled.update({\"ecat\" : (misspelled[\"ecat\"][0], \"ecatt\")})\n",
    "misspelled.update({\"spontanoues\" : (misspelled[\"spontanoues\"][0], \"spontaneous\")})\n",
    "misspelled.update({\"sapu\" : (misspelled[\"sapu\"][0], \"saapu\")})\n",
    "misspelled.update({\"ethol\" : (misspelled[\"ethol\"][0], \"ethanol\")})\n",
    "misspelled.update({\"sucidial\" : (misspelled[\"sucidial\"][0], \"suicidal\")})\n",
    "misspelled.update({\"incont\" : (misspelled[\"incont\"][0], \"incontinent\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd565f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/spelling_correction/rmh_misspelled_dict.txt', 'wb') as f:\n",
    "    pickle.dump(misspelled, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
